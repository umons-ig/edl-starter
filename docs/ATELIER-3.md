# üöÄ Atelier 3 : Base de Donn√©es et D√©ploiement en Production

**Dur√©e estim√©e :** 3h00
**Pr√©requis :** Ateliers 1 & 2 termin√©s + compte GitHub

## üéØ Objectifs de l'Atelier

√Ä la fin de cet atelier, vous aurez :

1. ‚úÖ Migr√© vers **PostgreSQL** avec SQLAlchemy ORM
2. ‚úÖ D√©ploy√© automatiquement avec **render.yaml** (Infrastructure as Code)
3. ‚úÖ Ajout√© de **nouvelles fonctionnalit√©s** (filtrage, recherche, statistiques)
4. ‚úÖ V√©rifi√© le **d√©ploiement automatique** (Continuous Deployment)

---

## üì¶ Architecture Cible

**Avant (Local - Stockage en m√©moire) :**
```
Frontend (localhost:5173) ‚Üê ‚Üí Backend (localhost:8000)
                                  ‚Üì
                            Liste Python (RAM)
                            ‚ùå Donn√©es perdues au red√©marrage
```

**Apr√®s (Production avec PostgreSQL) :**
```
Frontend (Render)                Backend (Render)              Database (Render)
taskflow-frontend.onrender.com ‚Üí taskflow-backend.onrender.com ‚Üí PostgreSQL
         HTTPS                            HTTPS + CORS                256 MB
                                                                  ‚úÖ Donn√©es persistantes
```

---

## Phase 1 : Migration vers PostgreSQL (60 min)

### üéØ Pourquoi PostgreSQL ?

**Probl√®me actuel :** Les donn√©es sont stock√©es dans une liste Python en m√©moire
- ‚ùå Donn√©es perdues √† chaque red√©marrage
- ‚ùå Impossible de scaler (plusieurs instances)
- ‚ùå Pas de requ√™tes complexes

**Avec PostgreSQL :**
- ‚úÖ Donn√©es persistantes
- ‚úÖ Requ√™tes SQL puissantes
- ‚úÖ Base de donn√©es professionnelle
- ‚úÖ Gratuit sur Render

---

### √âtape 1.1 : Installer les D√©pendances

```bash
cd backend
uv add sqlalchemy psycopg2-binary
```

**Ce que font ces packages :**
- `sqlalchemy` : ORM (Object-Relational Mapping) pour Python
- `psycopg2-binary` : Driver PostgreSQL

V√©rifiez l'installation :
```bash
uv run python -c "import sqlalchemy; print(f'SQLAlchemy {sqlalchemy.__version__}')"
```

---

### √âtape 1.2 : Cr√©er `backend/src/database.py`

Ce fichier configure la connexion √† la base de donn√©es.

```python
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session, declarative_base
from typing import Generator
import logging

logger = logging.getLogger("taskflow")

# Lire l'URL de la base de donn√©es depuis l'environnement
# Par d√©faut : SQLite pour le d√©veloppement local
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./taskflow.db")

# Fix pour Render : postgres:// ‚Üí postgresql://
if DATABASE_URL.startswith("postgres://"):
    DATABASE_URL = DATABASE_URL.replace("postgres://", "postgresql://", 1)

# Configuration du moteur SQLAlchemy
engine_kwargs = {}
if DATABASE_URL.startswith("sqlite"):
    # SQLite : d√©sactiver le check_same_thread
    engine_kwargs["connect_args"] = {"check_same_thread": False}
else:
    # PostgreSQL : configuration de la pool de connexions
    engine_kwargs.update({
        "pool_size": 5,           # 5 connexions dans la pool
        "max_overflow": 10,       # 10 connexions suppl√©mentaires max
        "pool_pre_ping": True,    # V√©rifier que la connexion est vivante
    })

# Cr√©er le moteur SQLAlchemy
engine = create_engine(DATABASE_URL, **engine_kwargs)

# Cr√©er la factory de sessions
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base pour les mod√®les ORM
Base = declarative_base()

def get_db() -> Generator[Session, None, None]:
    """
    Dependency function pour obtenir une session de base de donn√©es.
    Utilis√©e avec FastAPI Depends().
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def init_db() -> None:
    """Initialise la base de donn√©es en cr√©ant toutes les tables."""
    logger.info("üóÑÔ∏è  Initializing database tables...")
    Base.metadata.create_all(bind=engine)
    logger.info("‚úÖ Database tables created successfully!")
```

**Ce que fait ce fichier :**
- Supporte SQLite (local) et PostgreSQL (production)
- Configure une pool de connexions pour PostgreSQL
- Fournit `get_db()` pour FastAPI Depends
- Fournit `init_db()` pour cr√©er les tables

---

### √âtape 1.3 : Cr√©er `backend/src/models.py`

Ce fichier d√©finit le sch√©ma de la table `tasks`.

```python
from sqlalchemy import Column, String, DateTime, Enum as SQLEnum
from sqlalchemy.sql import func
from .database import Base
from enum import Enum

class TaskStatus(str, Enum):
    """Statuts possibles d'une t√¢che."""
    TODO = "todo"
    IN_PROGRESS = "in_progress"
    DONE = "done"

class TaskPriority(str, Enum):
    """Priorit√©s possibles d'une t√¢che."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"

class TaskModel(Base):
    """Mod√®le SQLAlchemy pour la table tasks."""
    __tablename__ = "tasks"

    # Colonnes
    id = Column(String, primary_key=True, index=True)
    title = Column(String(200), nullable=False)
    description = Column(String(1000), nullable=True)
    status = Column(
        SQLEnum(TaskStatus, values_callable=lambda x: [e.value for e in x]),
        nullable=False,
        default=TaskStatus.TODO.value
    )
    priority = Column(
        SQLEnum(TaskPriority, values_callable=lambda x: [e.value for e in x]),
        nullable=False,
        default=TaskPriority.MEDIUM.value
    )
    assignee = Column(String(100), nullable=True)
    due_date = Column(DateTime, nullable=True)
    created_at = Column(DateTime, nullable=False, server_default=func.now())
    updated_at = Column(DateTime, nullable=False, server_default=func.now(), onupdate=func.now())
```

**Ce que fait ce fichier :**
- D√©finit la structure de la table `tasks`
- Chaque `Column` = une colonne SQL
- Les `Enum` d√©finissent les valeurs valides
- `created_at` et `updated_at` automatiques

---

### √âtape 1.4 : Migrer `backend/src/app.py`

**Modifications √† apporter :**

#### **1. Importer les nouveaux modules**

Ajoutez en haut du fichier :
```python
from sqlalchemy.orm import Session
from sqlalchemy import text
from .database import get_db, init_db
from .models import TaskModel, TaskStatus, TaskPriority
```

#### **2. Supprimer l'ancien code**

**‚ùå SUPPRIMEZ ces lignes :**
```python
# SUPPRIMEZ les d√©finitions d'Enum (maintenant dans models.py)
class TaskStatus(str, Enum):
    ...

class TaskPriority(str, Enum):
    ...

# SUPPRIMEZ le stockage en m√©moire
tasks_storage: List[Task] = []
```

#### **3. Modifier la fonction lifespan**

**Remplacez :**
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifespan context manager for startup/shutdown events."""
    logger.info("üöÄ Starting TaskFlow backend...")
    yield
    logger.info("üëã Shutting down TaskFlow backend...")
```

**Par :**
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifespan context manager for startup/shutdown events."""
    logger.info("üöÄ Starting TaskFlow backend...")

    # Initialiser la base de donn√©es (cr√©er les tables)
    init_db()

    yield
    logger.info("üëã Shutting down TaskFlow backend...")
```

#### **4. Modifier tous les endpoints**

**GET /tasks :**
```python
@app.get("/tasks", response_model=list[Task])
async def get_tasks(db: Session = Depends(get_db)):
    """Get all tasks."""
    logger.info("Fetching all tasks")
    db_tasks = db.query(TaskModel).all()
    return db_tasks
```

**POST /tasks :**
```python
@app.post("/tasks", response_model=Task, status_code=201)
async def create_task(task_data: TaskCreate, db: Session = Depends(get_db)):
    logger.info(f"Creating task: {task_data.title}")

    db_task = TaskModel(
        id=str(uuid4()),
        **task_data.model_dump()
    )

    db.add(db_task)
    db.commit()
    db.refresh(db_task)

    logger.info(f"Task created successfully: {db_task.id}")
    return db_task
```

**GET /tasks/{task_id} :**
```python
@app.get("/tasks/{task_id}", response_model=Task)
async def get_task(task_id: str, db: Session = Depends(get_db)):
    logger.info(f"Fetching task: {task_id}")

    db_task = db.query(TaskModel).filter(TaskModel.id == task_id).first()
    if not db_task:
        raise HTTPException(status_code=404, detail="Task not found")

    return db_task
```

**PUT /tasks/{task_id} :**
```python
@app.put("/tasks/{task_id}", response_model=Task)
async def update_task(task_id: str, task_update: TaskUpdate, db: Session = Depends(get_db)):
    logger.info(f"Updating task: {task_id}")

    db_task = db.query(TaskModel).filter(TaskModel.id == task_id).first()
    if not db_task:
        raise HTTPException(status_code=404, detail="Task not found")

    update_data = task_update.model_dump(exclude_unset=True)
    for field, value in update_data.items():
        setattr(db_task, field, value)

    db.commit()
    db.refresh(db_task)

    logger.info(f"Task updated: {task_id}")
    return db_task
```

**DELETE /tasks/{task_id} :**
```python
@app.delete("/tasks/{task_id}", status_code=204)
async def delete_task(task_id: str, db: Session = Depends(get_db)):
    logger.info(f"Deleting task: {task_id}")

    db_task = db.query(TaskModel).filter(TaskModel.id == task_id).first()
    if not db_task:
        raise HTTPException(status_code=404, detail="Task not found")

    db.delete(db_task)
    db.commit()
    logger.info(f"Task deleted: {task_id}")
```

#### **5. Am√©liorer le Health Check**

```python
@app.get("/health")
async def health_check(db: Session = Depends(get_db)):
    """Health check endpoint with database connectivity test."""
    try:
        # Tester la connexion √† la base de donn√©es
        db.execute(text("SELECT 1"))
        db_status = "connected"

        # Compter les t√¢ches
        tasks_count = db.query(TaskModel).count()
    except Exception as e:
        logger.error(f"Database health check failed: {e}")
        db_status = "disconnected"
        tasks_count = 0

    return {
        "status": "healthy",
        "database": db_status,
        "tasks_count": tasks_count,
        "timestamp": datetime.utcnow().isoformat(),
        "environment": os.getenv("ENVIRONMENT", "development"),
        "version": "1.0.0"
    }
```

---

### √âtape 1.5 : Adapter les Tests

Modifiez `backend/tests/conftest.py` :

```python
import pytest
import tempfile
import os as os_module
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from src.app import app
from src.database import Base, get_db
from src.models import TaskModel

# Cr√©er une base de donn√©es de test temporaire
TEST_DB_FILE = tempfile.mktemp(suffix=".db")
TEST_DATABASE_URL = f"sqlite:///{TEST_DB_FILE}"

test_engine = create_engine(
    TEST_DATABASE_URL,
    connect_args={"check_same_thread": False},
)

TestSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=test_engine)

@pytest.fixture(scope="session", autouse=True)
def setup_test_database():
    """Cr√©er les tables de test une seule fois pour toute la session."""
    Base.metadata.create_all(bind=test_engine)
    yield
    # Nettoyer apr√®s tous les tests
    Base.metadata.drop_all(bind=test_engine)
    if os_module.path.exists(TEST_DB_FILE):
        os_module.remove(TEST_DB_FILE)

@pytest.fixture(autouse=True)
def clear_test_data():
    """Nettoyer les donn√©es entre chaque test."""
    session = TestSessionLocal()
    try:
        session.query(TaskModel).delete()
        session.commit()
    finally:
        session.close()
    yield

@pytest.fixture
def client():
    """Fournir un client de test avec une base de donn√©es de test."""
    def override_get_db():
        session = TestSessionLocal()
        try:
            yield session
        finally:
            session.close()

    app.dependency_overrides[get_db] = override_get_db

    try:
        with TestClient(app) as test_client:
            yield test_client
    finally:
        app.dependency_overrides.clear()
```

---

### √âtape 1.6 : Tester Localement

```bash
cd backend

# Lancer les tests
uv run pytest -v

# Lancer le serveur
uv run uvicorn src.app:app --reload

# Dans un autre terminal, tester
curl http://localhost:8000/health
curl http://localhost:8000/tasks

# Cr√©er une t√¢che
curl -X POST http://localhost:8000/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Test PostgreSQL",
    "status": "todo",
    "priority": "high"
  }'
```

‚úÖ **Checkpoint :** Vous devriez voir un fichier `taskflow.db` cr√©√© dans `backend/`

---

## Phase 2 : D√©ploiement avec render.yaml (45 min)

### √âtape 2.1 : Cr√©er un Compte Render

1. Allez sur https://render.com
2. Cliquez **"Get Started"**
3. Inscrivez-vous avec votre compte **GitHub**
4. Autorisez Render √† acc√©der √† vos repositories

---

### √âtape 2.2 : Comprendre render.yaml

Le fichier `render.yaml` √† la racine d√©finit toute l'infrastructure :

```yaml
databases:
  # PostgreSQL Database
  - name: taskflow-db
    databaseName: taskflow
    region: frankfurt
    plan: free
    user: taskflow

services:
  # Backend Service - FastAPI
  - type: web
    name: taskflow-backend
    runtime: python
    region: frankfurt
    plan: free
    branch: main
    buildCommand: "cd backend && pip install uv && uv sync"
    startCommand: "cd backend && uv run uvicorn src.app:app --host 0.0.0.0 --port $PORT"
    envVars:
      - key: PYTHON_VERSION
        value: "3.11"
      - key: ENVIRONMENT
        value: "production"
      - key: CORS_ORIGINS
        sync: false  # √Ä configurer manuellement
      - key: DATABASE_URL
        fromDatabase:
          name: taskflow-db
          property: connectionString  # ‚úÖ Connexion automatique !
    healthCheckPath: /health

  # Frontend Service - React + Vite
  - type: web
    name: taskflow-frontend
    runtime: static
    region: frankfurt
    plan: free
    branch: main
    buildCommand: "cd frontend && npm ci && npm run build"
    staticPublishPath: frontend/dist
    envVars:
      - key: VITE_API_URL
        sync: false  # √Ä configurer manuellement
```

**Ce que Render fait automatiquement :**
- ‚úÖ Cr√©e la base PostgreSQL
- ‚úÖ Injecte `DATABASE_URL` dans le backend
- ‚úÖ Build et d√©ploie backend + frontend
- ‚úÖ Configure HTTPS partout
- ‚úÖ Active health checks

---

### √âtape 2.3 : D√©ployer avec Blueprint

1. Dashboard Render : https://dashboard.render.com
2. Cliquez **"New +"** ‚Üí **"Blueprint"**
3. S√©lectionnez votre repository **"edl-tp-1"**
4. Render d√©tecte `render.yaml`
5. Cliquez **"Apply"**

‚è≥ **Attendez 5-7 minutes** pour le d√©ploiement complet.

**Notez les URLs :**
```
Backend:  https://taskflow-backend-XXXX.onrender.com
Frontend: https://taskflow-frontend-YYYY.onrender.com
```

---

### √âtape 2.4 : Configurer CORS et URLs

**Backend ‚Üí Environment :**
```
CORS_ORIGINS = https://taskflow-frontend-YYYY.onrender.com
```

**Frontend ‚Üí Environment :**
```
VITE_API_URL = https://taskflow-backend-XXXX.onrender.com
```

Attendez les red√©ploiements automatiques (2-3 min chacun).

---

### √âtape 2.5 : V√©rifier le D√©ploiement

```bash
# Health check (doit montrer "database": "connected")
curl https://taskflow-backend-XXXX.onrender.com/health

# Cr√©er une t√¢che
curl -X POST https://taskflow-backend-XXXX.onrender.com/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Production test",
    "status": "todo",
    "priority": "high"
  }'

# Lister les t√¢ches
curl https://taskflow-backend-XXXX.onrender.com/tasks
```

Testez aussi depuis le frontend : `https://taskflow-frontend-YYYY.onrender.com`

‚úÖ **Checkpoint :** L'application fonctionne en production avec PostgreSQL !

---

## Phase 3 : V√©rification et Tests (30 min)

### √âtape 3.1 : Tester l'API Directement

Une fois d√©ploy√©, testez tous les endpoints de l'API :

**Health Check :**
```bash
curl https://taskflow-backend-XXXX.onrender.com/health
```

Vous devriez voir :
```json
{
  "status": "healthy",
  "database": "connected",
  "tasks_count": 0,
  "timestamp": "2025-01-21T10:00:00",
  "environment": "production",
  "version": "1.0.0"
}
```

**Cr√©er une t√¢che :**
```bash
curl -X POST https://taskflow-backend-XXXX.onrender.com/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Premi√®re t√¢che en production",
    "description": "Test du d√©ploiement",
    "status": "todo",
    "priority": "high"
  }'
```

**Lister les t√¢ches :**
```bash
curl https://taskflow-backend-XXXX.onrender.com/tasks
```

**R√©cup√©rer une t√¢che par ID :**
```bash
curl https://taskflow-backend-XXXX.onrender.com/tasks/{TASK_ID}
```

---

### √âtape 3.2 : Tester le Frontend en Production

1. Ouvrez `https://taskflow-frontend-YYYY.onrender.com`
2. **Cr√©ez plusieurs t√¢ches** avec diff√©rents statuts et priorit√©s
3. **Modifiez une t√¢che** (changez son statut)
4. **Supprimez une t√¢che**

‚úÖ **Tout doit fonctionner !**

---

### √âtape 3.3 : V√©rifier la Persistence des Donn√©es

**Test de persistance PostgreSQL :**

1. Cr√©ez 3-4 t√¢ches depuis le frontend
2. Allez sur Render Dashboard ‚Üí **taskflow-backend**
3. Cliquez **Manual Deploy** ‚Üí **Deploy latest commit**
4. Attendez le red√©ploiement (2-3 minutes)
5. Rafra√Æchissez votre frontend

‚úÖ **Les t√¢ches sont toujours l√† !** PostgreSQL conserve les donn√©es entre les red√©marrages.

---

### √âtape 3.4 : Explorer la Base de Donn√©es PostgreSQL

Allez voir directement dans la base de donn√©es :

1. Dashboard ‚Üí **taskflow-db** ‚Üí **Shell**
2. Dans le shell PostgreSQL :

```sql
-- Voir toutes les tables
\dt

-- Voir les colonnes de la table tasks
\d tasks

-- Voir toutes les t√¢ches
SELECT id, title, status, priority, created_at FROM tasks;

-- Compter les t√¢ches par statut
SELECT status, COUNT(*) FROM tasks GROUP BY status;
```

‚úÖ **Vous voyez vos donn√©es !** Elles sont bien stock√©es dans PostgreSQL.

---

### √âtape 3.5 : V√©rifier les Logs

**Backend logs :**

1. Dashboard ‚Üí **taskflow-backend** ‚Üí **Logs**
2. Vous devriez voir :
   ```
   üöÄ Starting TaskFlow backend...
   üóÑÔ∏è  Initializing database tables...
   ‚úÖ Database tables created successfully!
   üåê CORS enabled for origins: ['https://taskflow-frontend-YYYY.onrender.com']
   INFO:     Application startup complete.
   ```

3. Cr√©ez une t√¢che depuis le frontend
4. Observez les logs en temps r√©el :
   ```
   INFO: Creating task: Premi√®re t√¢che
   INFO: Task created successfully: abc-123-def
   ```

‚úÖ **Checkpoint :** Le d√©ploiement fonctionne parfaitement !

---

## Phase 4 : Ajouter une Fonctionnalit√© + Auto-Deploy (45 min)

Maintenant, ajoutons une petite fonctionnalit√© simple pour d√©montrer le d√©ploiement automatique.

### √âtape 4.1 : Ajouter un Endpoint Simple de Comptage

Ajoutez un endpoint simple dans `backend/src/app.py` (avant les autres endpoints) :

```python
@app.get("/tasks/count")
async def count_tasks(db: Session = Depends(get_db)):
    """Count total number of tasks."""
    logger.info("Counting tasks")
    total = db.query(TaskModel).count()
    return {"total": total}
```

**Testez localement :**
```bash
# Dans un terminal, lancez le serveur
cd backend
uv run uvicorn src.app:app --reload

# Dans un autre terminal
curl http://localhost:8000/tasks/count
```

Vous devriez voir :
```json
{"total": 0}
```

---

### √âtape 4.2 : Ajouter un Test Simple

Cr√©ez `backend/tests/test_count.py` :

```python
def test_count_tasks(client):
    """Test counting tasks."""
    # Au d√©but, 0 t√¢ches
    response = client.get("/tasks/count")
    assert response.status_code == 200
    assert response.json()["total"] == 0

    # Cr√©er 3 t√¢ches
    for i in range(3):
        client.post("/tasks", json={
            "title": f"Task {i+1}",
            "status": "todo",
            "priority": "medium"
        })

    # Maintenant, 3 t√¢ches
    response = client.get("/tasks/count")
    assert response.status_code == 200
    assert response.json()["total"] == 3
```

**Lancez les tests :**
```bash
cd backend
uv run pytest -v
```

‚úÖ **Tous les tests doivent passer !**

---

### √âtape 4.3 : Commit et Push vers GitHub

```bash
git add .
git commit -m "feat: add task count endpoint

- Add GET /tasks/count endpoint
- Add test for count endpoint
- Returns total number of tasks in database

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"

git push origin main
```

---

### √âtape 4.4 : Observer le Pipeline CI/CD

**1. GitHub Actions (1-2 min) :**
- Allez sur GitHub ‚Üí **Actions**
- Un nouveau workflow d√©marre automatiquement
- Observez :
  - ‚úÖ Backend tests (pytest)
  - ‚úÖ Frontend tests (vitest)

**2. Render Auto-Deploy (3-5 min) :**
- Allez sur Render Dashboard
- Cliquez sur **taskflow-backend**
- Vous verrez "Deploying..." en haut
- Observez les logs en temps r√©el :

```log
==> Cloning from https://github.com/...
==> Checking out commit abc123...
==> Running build command 'cd backend && pip install uv && uv sync'...
==> Installing dependencies...
==> Build successful!
==> Starting server...
üöÄ Starting TaskFlow backend...
üóÑÔ∏è  Initializing database tables...
‚úÖ Database tables created successfully!
```

---

### √âtape 4.5 : V√©rifier la Nouvelle Fonctionnalit√© en Production

Une fois le d√©ploiement termin√© (indicateur vert ‚úÖ) :

**Tester le nouveau endpoint :**
```bash
curl https://taskflow-backend-XXXX.onrender.com/tasks/count
```

**V√©rifier dans la documentation Swagger :**
1. Ouvrez : `https://taskflow-backend-XXXX.onrender.com/docs`
2. Vous devriez voir le nouveau endpoint `GET /tasks/count`
3. Cliquez sur **"Try it out"** ‚Üí **"Execute"**
4. Vous verrez le nombre total de t√¢ches

‚úÖ **La nouvelle fonctionnalit√© est d√©ploy√©e automatiquement !**

---

### √âtape 4.6 : Comprendre le Workflow Complet

**Ce qui s'est pass√© automatiquement :**

```
1. git push origin main
   ‚Üì
2. GitHub Actions d√©marre
   ‚îú‚îÄ Backend: uv run pytest ‚úÖ
   ‚îú‚îÄ Frontend: npm test ‚úÖ
   ‚îî‚îÄ Les tests passent
   ‚Üì
3. Render d√©tecte le push
   ‚Üì
4. Render clone le nouveau code
   ‚Üì
5. Render rebuild le backend
   ‚îú‚îÄ pip install uv
   ‚îú‚îÄ uv sync (install dependencies)
   ‚îî‚îÄ uv run uvicorn (start server)
   ‚Üì
6. Health check: /health ‚úÖ
   ‚Üì
7. üéâ Nouvelle version LIVE !

Temps total: ~5-7 minutes
```

**Zero configuration n√©cessaire !** Tout est automatique gr√¢ce √† :
- `.github/workflows/backend.yml` (tests)
- `render.yaml` (d√©ploiement)

---

## üìä Ce que Vous Avez Appris

‚úÖ **SQLAlchemy ORM** - Mod√®les Python ‚Üî Tables SQL
‚úÖ **PostgreSQL** - Base de donn√©es relationnelle professionnelle
‚úÖ **Infrastructure as Code** - render.yaml pour d√©finir l'infra
‚úÖ **Continuous Deployment** - Push ‚Üí Tests ‚Üí Deploy automatique
‚úÖ **API REST** - Nouveaux endpoints avec tests
‚úÖ **Production monitoring** - Logs, health checks, database status
‚úÖ **Data persistence** - Les donn√©es survivent aux red√©marrages

---

## üöÄ Pour Aller Plus Loin

### Fonctionnalit√©s Simples (30 min chacune)

1. **Endpoint de recherche** : `GET /tasks/search?q=query`
2. **Endpoint de filtrage** : `GET /tasks/filter/{status}`
3. **Endpoint de statistiques** : `GET /tasks/stats` (compte par statut/priorit√©)
4. **Afficher le count dans le frontend** : Badge avec nombre total de t√¢ches

### Fonctionnalit√©s Avanc√©es (1-2h chacune)

1. **Pagination** : Ajouter `skip` et `limit` aux endpoints
2. **Authentification** : JWT tokens avec FastAPI Security
3. **Filtrage UI** : Boutons pour filtrer par statut dans le frontend
4. **Dashboard de stats** : Graphiques avec Chart.js

### DevOps Avanc√©

1. **Monitoring** : Int√©grer Sentry pour error tracking
2. **Staging Environment** : Environnement de pr√©-production
3. **Database Migrations** : Alembic pour migrations SQL
4. **Custom Domain** : Utiliser votre propre nom de domaine

---

## üìö Ressources

**Documentation Technique :**
- [SQLAlchemy Docs](https://docs.sqlalchemy.org/)
- [FastAPI Database Guide](https://fastapi.tiangolo.com/tutorial/sql-databases/)
- [Render Blueprint Spec](https://render.com/docs/blueprint-spec)
- [PostgreSQL Docs](https://www.postgresql.org/docs/)

**Atelier Extensions :**
- [Backend README](../backend/README.md) - Documentation compl√®te du backend
- [DEPLOYMENT.md](../DEPLOYMENT.md) - Guide de d√©ploiement d√©taill√©

---

## ‚úÖ Checklist de Fin d'Atelier

**Migration PostgreSQL :**
- [ ] `database.py` cr√©√© avec configuration SQLAlchemy
- [ ] `models.py` cr√©√© avec `TaskModel`
- [ ] `app.py` migr√© pour utiliser la DB
- [ ] Tests adapt√©s avec base de test temporaire
- [ ] Tests locaux passent avec SQLite

**D√©ploiement :**
- [ ] Compte Render cr√©√© et connect√© √† GitHub
- [ ] `render.yaml` compris et expliqu√©
- [ ] Blueprint d√©ploy√© avec succ√®s
- [ ] Backend accessible via HTTPS
- [ ] Frontend accessible via HTTPS
- [ ] CORS configur√© correctement
- [ ] PostgreSQL connect√©e (health check montre "connected")

**Nouvelle Fonctionnalit√© :**
- [ ] Endpoint `/tasks/count` impl√©ment√© et test√©
- [ ] Test unitaire pour le comptage
- [ ] Documentation Swagger affiche le nouvel endpoint

**Continuous Deployment :**
- [ ] Push vers main d√©clenche GitHub Actions
- [ ] Tests passent automatiquement
- [ ] Render auto-deploy fonctionne
- [ ] Nouvelles fonctionnalit√©s visibles en production
- [ ] Donn√©es persistent apr√®s red√©ploiement

**Si tout est coch√© : Bravo, vous ma√Ætrisez le cycle complet ! üéâüöÄ**

---

**Version 4.0** - Atelier 3 : Base de Donn√©es et D√©ploiement en Production (3h)
