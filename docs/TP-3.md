# üöÄ TP 3 : Base de Donn√©es et D√©ploiement en Production

**Dur√©e estim√©e :** 3h00
**Pr√©requis :** TP 1 & 2 termin√©s + compte GitHub

## üéØ Objectifs de l'Atelier

√Ä la fin de cet atelier, vous aurez :

1. ‚úÖ Migr√© vers **PostgreSQL** avec SQLAlchemy ORM
2. ‚úÖ D√©ploy√© automatiquement avec **render.yaml** (Infrastructure as Code)
3. ‚úÖ Ajout√© de **nouvelles fonctionnalit√©s** (comptage de t√¢ches)
4. ‚úÖ V√©rifi√© le **d√©ploiement automatique** (Continuous Deployment)

---

## üì¶ Architecture Cible

**Avant (Local - Stockage en m√©moire) :**
```
Frontend (localhost:5173) ‚Üê ‚Üí Backend (localhost:8000)
                                  ‚Üì
                            Liste Python (RAM)
                            ‚ùå Donn√©es perdues au red√©marrage
```

**Apr√®s (Production avec PostgreSQL) :**
```
Frontend (Render)                Backend (Render)              Database (Render)
taskflow-frontend.onrender.com ‚Üí taskflow-backend.onrender.com ‚Üí PostgreSQL
         HTTPS                            HTTPS + CORS                256 MB
                                                                  ‚úÖ Donn√©es persistantes
```

---

## üéØ Pourquoi PostgreSQL ?

**Probl√®me actuel :** Les donn√©es sont stock√©es dans une liste Python en m√©moire
- ‚ùå Donn√©es perdues √† chaque red√©marrage
- ‚ùå Impossible de scaler (plusieurs instances)
- ‚ùå Pas de requ√™tes complexes

**Avec PostgreSQL :**
- ‚úÖ Donn√©es persistantes
- ‚úÖ Requ√™tes SQL puissantes
- ‚úÖ Base de donn√©es professionnelle
- ‚úÖ Gratuit sur Render

---

## ‚úçÔ∏è Exercice 1 : Installer les D√©pendances PostgreSQL

### Objectif
Ajouter SQLAlchemy et le driver PostgreSQL au backend.

### Instructions

1. **Ajoutez les packages n√©cessaires :**
   ```bash
   cd backend
   uv add sqlalchemy psycopg2-binary
   ```

2. **V√©rifiez l'installation :**
   ```bash
   uv run python -c "import sqlalchemy; print(f'SQLAlchemy {sqlalchemy.__version__}')"
   ```

### ‚úÖ R√©sultat attendu
Vous devriez voir la version de SQLAlchemy s'afficher (ex: `SQLAlchemy 2.0.25`)

### üí° Ce que font ces packages
- **`sqlalchemy`** : ORM (Object-Relational Mapping) pour Python - permet de manipuler la base de donn√©es avec des objets Python
- **`psycopg2-binary`** : Driver PostgreSQL - permet √† Python de se connecter √† PostgreSQL

---

## ‚úçÔ∏è Exercice 2 : Configurer la Base de Donn√©es

### Objectif
Cr√©er le fichier de configuration pour la connexion √† la base de donn√©es.

### Instructions

1. **Cr√©ez le fichier `backend/src/database.py`**

2. **Ajoutez la configuration suivante :**
   - Importer les modules n√©cessaires : `sqlalchemy`, `sessionmaker`, `declarative_base`
   - Lire `DATABASE_URL` depuis les variables d'environnement (d√©faut: `sqlite:///./taskflow.db`)
   - Cr√©er un moteur SQLAlchemy avec `create_engine()`
   - Pour SQLite : ajouter `connect_args={"check_same_thread": False}`
   - Pour PostgreSQL : configurer la pool de connexions avec `pool_size=5`, `max_overflow=10`, `pool_pre_ping=True`
   - Cr√©er une factory de sessions avec `sessionmaker()`
   - Cr√©er une `Base` avec `declarative_base()` pour les mod√®les ORM

3. **Ajoutez deux fonctions :**
   - `get_db()` : G√©n√©rateur qui fournit une session de base de donn√©es (pour FastAPI Depends)
   - `init_db()` : Initialise la base de donn√©es en cr√©ant toutes les tables

### üí° Points importants
- **`DATABASE_URL`** : URL de connexion (SQLite en local, PostgreSQL en production)
- **Pool de connexions** : R√©utilise les connexions pour am√©liorer les performances
- **`pool_pre_ping`** : V√©rifie que la connexion est vivante avant de l'utiliser

---

## ‚úçÔ∏è Exercice 3 : Cr√©er le Mod√®le de Donn√©es

### Objectif
D√©finir le sch√©ma de la table `tasks` avec SQLAlchemy ORM.

### Instructions

1. **Cr√©ez le fichier `backend/src/models.py`**

2. **D√©placez les enums depuis `app.py` :**
   - `TaskStatus` : todo, in_progress, done
   - `TaskPriority` : low, medium, high

3. **Cr√©ez la classe `TaskModel` qui h√©rite de `Base` :**
   - D√©finir `__tablename__ = "tasks"`
   - Ajouter les colonnes avec `Column()` :
     - `id` : String, primary key, index
     - `title` : String(200), non nullable
     - `description` : String(1000), nullable
     - `status` : Enum (TaskStatus), d√©faut TODO
     - `priority` : Enum (TaskPriority), d√©faut MEDIUM
     - `assignee` : String(100), nullable
     - `due_date` : DateTime, nullable
     - `created_at` : DateTime, auto (server_default=func.now())
     - `updated_at` : DateTime, auto (server_default=func.now(), onupdate=func.now())

### üí° Avantages de l'ORM
- Pas besoin d'√©crire du SQL directement
- Type-safety avec Python
- Migrations de sch√©ma facilit√©es
- Timestamps automatiques

---

## ‚úçÔ∏è Exercice 4 : Migrer l'Application vers PostgreSQL

### Objectif
Adapter `app.py` pour utiliser SQLAlchemy au lieu du stockage en m√©moire.

### Instructions

**Partie 1 : Imports et nettoyage**

1. **Ajoutez les imports n√©cessaires :**
   - `from sqlalchemy.orm import Session`
   - `from sqlalchemy import text`
   - `from .database import get_db, init_db`
   - `from .models import TaskModel, TaskStatus, TaskPriority`

2. **Supprimez l'ancien code :**
   - ‚ùå Supprimez les d√©finitions de `TaskStatus` et `TaskPriority` (maintenant dans models.py)
   - ‚ùå Supprimez `tasks_storage: List[Task] = []`
   - ‚ùå Supprimez les fonctions `clear_tasks()` et `get_tasks_storage()`

**Partie 2 : Modifier le lifespan**

3. **Dans la fonction `lifespan()`, appelez `init_db()` au d√©marrage**

**Partie 3 : Modifier les endpoints (utilisez `db: Session = Depends(get_db)`)**

4. **GET /tasks :**
   - R√©cup√©rer toutes les t√¢ches avec `db.query(TaskModel).all()`

5. **POST /tasks :**
   - Cr√©er un `TaskModel` avec les donn√©es re√ßues
   - Ajouter √† la session avec `db.add()`
   - Sauvegarder avec `db.commit()`
   - Rafra√Æchir avec `db.refresh()`

6. **GET /tasks/{task_id} :**
   - Chercher avec `db.query(TaskModel).filter(TaskModel.id == task_id).first()`
   - Lever `HTTPException(404)` si non trouv√©

7. **PUT /tasks/{task_id} :**
   - Chercher la t√¢che
   - Mettre √† jour les champs avec `setattr()`
   - Commit et refresh

8. **DELETE /tasks/{task_id} :**
   - Chercher la t√¢che
   - Supprimer avec `db.delete()`
   - Commit

9. **Am√©liorer /health :**
   - Tester la connexion DB avec `db.execute(text("SELECT 1"))`
   - Compter les t√¢ches avec `db.query(TaskModel).count()`
   - Retourner le statut de la DB et le nombre de t√¢ches

### ‚úÖ Checkpoint
Testez localement :
```bash
cd backend
uv run uvicorn src.app:app --reload

# Dans un autre terminal
curl http://localhost:8000/health
curl http://localhost:8000/tasks
```

Vous devriez voir un fichier `taskflow.db` cr√©√© dans `backend/`

---

## ‚úçÔ∏è Exercice 5 : Adapter les Tests

### Objectif
Modifier les tests pour utiliser une base de donn√©es SQLite temporaire.

### Instructions

1. **Dans `backend/tests/conftest.py`, modifiez la fixture :**
   - Cr√©er une base de donn√©es de test temporaire avec `tempfile.mktemp()`
   - Cr√©er un moteur de test avec `create_engine(TEST_DATABASE_URL)`
   - Cr√©er une factory de sessions de test avec `sessionmaker()`
   - Fixture `setup_test_database` (scope="session") : cr√©er toutes les tables
   - Fixture `clear_test_data` (autouse=True) : nettoyer entre chaque test
   - Fixture `client` : override `get_db` pour utiliser la DB de test

2. **Lancez les tests :**
   ```bash
   cd backend
   uv run pytest -v
   ```

### ‚úÖ R√©sultat attendu
Tous les tests doivent passer (19+ tests)

---

## ‚úçÔ∏è Exercice 6 : Cr√©er un Compte Render

### Objectif
Pr√©parer le d√©ploiement sur Render.

### Instructions

1. **Cr√©er un compte Render :**
   - Allez sur https://render.com
   - Cliquez **"Get Started"**
   - Inscrivez-vous avec votre compte **GitHub**
   - Autorisez Render √† acc√©der √† vos repositories

2. **Explorez le Dashboard :**
   - Familiarisez-vous avec l'interface
   - Notez le bouton **"New +"** pour cr√©er des services

### üí° Render vs Heroku
- ‚úÖ Gratuit pour PostgreSQL + 2 services
- ‚úÖ D√©ploiement automatique depuis GitHub
- ‚úÖ Infrastructure as Code avec `render.yaml`
- ‚úÖ HTTPS automatique

---

## ‚úçÔ∏è Exercice 7 : Comprendre render.yaml

### Objectif
Comprendre l'Infrastructure as Code pour Render.

### Instructions

1. **Ouvrez `render.yaml` √† la racine du projet**

2. **Analysez la structure :**

**Section `databases` :**
- D√©finit une base PostgreSQL gratuite
- R√©gion : Frankfurt (proche de vous)
- Nom : `taskflow-db`

**Section `services` (Backend) :**
- Type : `web` (service HTTP)
- Runtime : `python`
- Build command : installe UV et les d√©pendances
- Start command : lance uvicorn
- Variables d'environnement :
  - `DATABASE_URL` : inject√©e automatiquement depuis la DB
  - `CORS_ORIGINS` : √† configurer manuellement
- Health check : `/health`

**Section `services` (Frontend) :**
- Type : `web`
- Runtime : `static` (site statique)
- Build command : `npm ci && npm run build`
- Publish path : `frontend/dist`
- Variable : `VITE_API_URL` √† configurer

### üí° Avantages de render.yaml
- ‚úÖ Toute l'infrastructure est versionn√©e dans Git
- ‚úÖ D√©ploiement reproductible
- ‚úÖ Cr√©ation automatique de tous les services
- ‚úÖ Injection automatique de DATABASE_URL

---

## ‚úçÔ∏è Exercice 8 : D√©ployer avec Blueprint

### Objectif
D√©ployer toute l'application sur Render en un clic.

### Instructions

1. **Assurez-vous que vos changements sont pouss√©s sur GitHub :**
   ```bash
   git add .
   git commit -m "feat: migrate to PostgreSQL with SQLAlchemy"
   git push origin main
   ```

2. **Sur Render Dashboard :**
   - Cliquez **"New +"** ‚Üí **"Blueprint"**
   - S√©lectionnez votre repository
   - Render d√©tecte automatiquement `render.yaml`
   - Cliquez **"Apply"**

3. **Attendez le d√©ploiement (5-7 minutes) :**
   - 3 services vont √™tre cr√©√©s :
     - `taskflow-db` (PostgreSQL)
     - `taskflow-backend` (FastAPI)
     - `taskflow-frontend` (React)

4. **Notez les URLs g√©n√©r√©es :**
   ```
   Backend:  https://taskflow-backend-XXXX.onrender.com
   Frontend: https://taskflow-frontend-YYYY.onrender.com
   ```

### ‚è≥ Pendant l'attente
Observez les logs de build en temps r√©el pour chaque service.

---

## ‚úçÔ∏è Exercice 9 : Configurer CORS et API URL

### Objectif
Connecter le frontend au backend en production.

### Instructions

1. **Configurer le Backend :**
   - Dashboard ‚Üí **taskflow-backend** ‚Üí **Environment**
   - Ajoutez : `CORS_ORIGINS = https://taskflow-frontend-YYYY.onrender.com`
   - (Remplacez YYYY par votre ID frontend)
   - Cliquez **"Save Changes"**
   - Attendez le red√©ploiement automatique (2-3 min)

2. **Configurer le Frontend :**
   - Dashboard ‚Üí **taskflow-frontend** ‚Üí **Environment**
   - Ajoutez : `VITE_API_URL = https://taskflow-backend-XXXX.onrender.com`
   - (Remplacez XXXX par votre ID backend)
   - Cliquez **"Save Changes"**
   - Attendez le red√©ploiement automatique (2-3 min)

### ‚úÖ R√©sultat attendu
Les deux services red√©marrent automatiquement avec les nouvelles configurations.

---

## ‚úçÔ∏è Exercice 10 : V√©rifier le D√©ploiement

### Objectif
Tester que tout fonctionne en production.

### Instructions

1. **Testez l'API Backend :**
   ```bash
   # Health check
   curl https://taskflow-backend-XXXX.onrender.com/health
   ```

   Vous devriez voir :
   ```json
   {
     "status": "healthy",
     "database": "connected",
     "tasks_count": 0,
     "environment": "production"
   }
   ```

2. **Cr√©ez une t√¢che :**
   ```bash
   curl -X POST https://taskflow-backend-XXXX.onrender.com/tasks \
     -H "Content-Type: application/json" \
     -d '{
       "title": "Test production",
       "status": "todo",
       "priority": "high"
     }'
   ```

3. **Listez les t√¢ches :**
   ```bash
   curl https://taskflow-backend-XXXX.onrender.com/tasks
   ```

4. **Testez le Frontend :**
   - Ouvrez `https://taskflow-frontend-YYYY.onrender.com`
   - Cr√©ez plusieurs t√¢ches
   - Modifiez une t√¢che
   - Supprimez une t√¢che

### ‚úÖ R√©sultat attendu
Tout fonctionne parfaitement! üéâ

---

## ‚úçÔ∏è Exercice 11 : V√©rifier la Persistence

### Objectif
Prouver que PostgreSQL persiste les donn√©es.

### Instructions

1. **Cr√©ez 3-4 t√¢ches depuis le frontend**

2. **Forcez un red√©ploiement :**
   - Dashboard ‚Üí **taskflow-backend**
   - Cliquez **"Manual Deploy"** ‚Üí **"Deploy latest commit"**
   - Attendez le red√©ploiement (2-3 minutes)

3. **Rafra√Æchissez votre frontend**

### ‚úÖ R√©sultat attendu
Les t√¢ches sont toujours l√†! PostgreSQL conserve les donn√©es entre les red√©marrages.

---

## ‚úçÔ∏è Exercice 12 : Explorer la Base de Donn√©es

### Objectif
Voir directement les donn√©es dans PostgreSQL.

### Instructions

1. **Ouvrez le shell PostgreSQL :**
   - Dashboard ‚Üí **taskflow-db** ‚Üí **Shell**

2. **Ex√©cutez ces commandes SQL :**
   ```sql
   -- Voir toutes les tables
   \dt

   -- Voir la structure de la table tasks
   \d tasks

   -- Voir toutes les t√¢ches
   SELECT id, title, status, priority, created_at FROM tasks;

   -- Compter les t√¢ches par statut
   SELECT status, COUNT(*) FROM tasks GROUP BY status;
   ```

### ‚úÖ R√©sultat attendu
Vous voyez vos donn√©es stock√©es dans PostgreSQL!

---

## ‚úçÔ∏è Exercice 13 : Ajouter une Nouvelle Fonctionnalit√©

### Objectif
D√©montrer le d√©ploiement automatique en ajoutant un endpoint simple.

### Instructions

1. **Dans `backend/src/app.py`, ajoutez un endpoint de comptage :**
   ```python
   @app.get("/tasks/count")
   async def count_tasks(db: Session = Depends(get_db)):
       """Count total number of tasks."""
       logger.info("Counting tasks")
       total = db.query(TaskModel).count()
       return {"total": total}
   ```

2. **Testez localement :**
   ```bash
   cd backend
   uv run uvicorn src.app:app --reload

   # Dans un autre terminal
   curl http://localhost:8000/tasks/count
   ```

3. **Ajoutez un test dans `backend/tests/test_count.py` :**
   ```python
   def test_count_tasks(client):
       """Test counting tasks."""
       # Au d√©but, 0 t√¢ches
       response = client.get("/tasks/count")
       assert response.status_code == 200
       assert response.json()["total"] == 0

       # Cr√©er 3 t√¢ches
       for i in range(3):
           client.post("/tasks", json={
               "title": f"Task {i+1}",
               "status": "todo",
               "priority": "medium"
           })

       # Maintenant, 3 t√¢ches
       response = client.get("/tasks/count")
       assert response.status_code == 200
       assert response.json()["total"] == 3
   ```

4. **V√©rifiez que les tests passent :**
   ```bash
   uv run pytest -v
   ```

### ‚úÖ R√©sultat attendu
Tous les tests passent (20+ tests maintenant)

---

## ‚úçÔ∏è Exercice 14 : D√©ployer la Nouvelle Fonctionnalit√©

### Objectif
Observer le cycle complet CI/CD automatique.

### Instructions

1. **Committez et poussez :**
   ```bash
   git add .
   git commit -m "feat: add task count endpoint

   - Add GET /tasks/count endpoint
   - Add test for count endpoint
   - Returns total number of tasks in database"

   git push origin main
   ```

2. **Observez GitHub Actions (1-2 min) :**
   - GitHub ‚Üí **Actions**
   - Workflow d√©marre automatiquement
   - Backend tests ‚úÖ
   - Frontend tests ‚úÖ

3. **Observez Render Auto-Deploy (3-5 min) :**
   - Render Dashboard ‚Üí **taskflow-backend**
   - Status : "Deploying..."
   - Observez les logs de build en temps r√©el

4. **Testez en production :**
   ```bash
   curl https://taskflow-backend-XXXX.onrender.com/tasks/count
   ```

5. **V√©rifiez dans Swagger UI :**
   - Ouvrez : `https://taskflow-backend-XXXX.onrender.com/docs`
   - Le nouveau endpoint `GET /tasks/count` appara√Æt
   - Testez-le avec "Try it out"

### ‚úÖ R√©sultat attendu
La nouvelle fonctionnalit√© est d√©ploy√©e automatiquement! üöÄ

---

## üìä Workflow Complet CI/CD

**Ce qui s'est pass√© automatiquement :**

```
1. git push origin main
   ‚Üì
2. GitHub Actions d√©marre
   ‚îú‚îÄ Backend: uv run pytest ‚úÖ
   ‚îú‚îÄ Frontend: npm test ‚úÖ
   ‚îî‚îÄ Les tests passent
   ‚Üì
3. Render d√©tecte le push
   ‚Üì
4. Render clone le nouveau code
   ‚Üì
5. Render rebuild le backend
   ‚îú‚îÄ pip install uv
   ‚îú‚îÄ uv sync (install dependencies)
   ‚îî‚îÄ uv run uvicorn (start server)
   ‚Üì
6. Health check: /health ‚úÖ
   ‚Üì
7. üéâ Nouvelle version LIVE !

Temps total: ~5-7 minutes
```

**Zero configuration n√©cessaire !** Tout est automatique gr√¢ce √† :
- `.github/workflows/backend.yml` (tests)
- `render.yaml` (d√©ploiement)

---

## üìã R√©capitulatif

F√©licitations ! Vous avez maintenant :

‚úÖ **Exercice 1** : Install√© SQLAlchemy et psycopg2
‚úÖ **Exercice 2** : Configur√© la connexion √† la base de donn√©es
‚úÖ **Exercice 3** : Cr√©√© le mod√®le ORM TaskModel
‚úÖ **Exercice 4** : Migr√© app.py vers PostgreSQL
‚úÖ **Exercice 5** : Adapt√© les tests avec une DB temporaire
‚úÖ **Exercice 6** : Cr√©√© un compte Render
‚úÖ **Exercice 7** : Compris render.yaml (IaC)
‚úÖ **Exercice 8** : D√©ploy√© avec Blueprint en un clic
‚úÖ **Exercice 9** : Configur√© CORS et API URL
‚úÖ **Exercice 10** : V√©rifi√© le d√©ploiement en production
‚úÖ **Exercice 11** : Prouv√© la persistence des donn√©es
‚úÖ **Exercice 12** : Explor√© PostgreSQL avec SQL
‚úÖ **Exercice 13** : Ajout√© un endpoint de comptage
‚úÖ **Exercice 14** : D√©ploy√© automatiquement avec CD

**Temps total estim√© :** 3 heures

---

## üìö Ce que Vous Avez Appris

‚úÖ **SQLAlchemy ORM** - Mod√®les Python ‚Üî Tables SQL
‚úÖ **PostgreSQL** - Base de donn√©es relationnelle professionnelle
‚úÖ **Infrastructure as Code** - render.yaml pour d√©finir l'infra
‚úÖ **Continuous Deployment** - Push ‚Üí Tests ‚Üí Deploy automatique
‚úÖ **API REST** - Nouveaux endpoints avec tests
‚úÖ **Production monitoring** - Logs, health checks, database status
‚úÖ **Data persistence** - Les donn√©es survivent aux red√©marrages

---

## üöÄ Pour Aller Plus Loin

### Fonctionnalit√©s Simples (30 min chacune)

1. **Endpoint de recherche** : `GET /tasks/search?q=query`
2. **Endpoint de filtrage** : `GET /tasks/filter/{status}`
3. **Endpoint de statistiques** : `GET /tasks/stats` (compte par statut/priorit√©)
4. **Badge de comptage** : Afficher le count dans le frontend

### Fonctionnalit√©s Avanc√©es (1-2h chacune)

1. **Pagination** : Ajouter `skip` et `limit` aux endpoints
2. **Authentification** : JWT tokens avec FastAPI Security
3. **Filtrage UI** : Boutons pour filtrer par statut dans le frontend
4. **Dashboard de stats** : Graphiques avec Chart.js

### DevOps Avanc√©

1. **Monitoring** : Int√©grer Sentry pour error tracking
2. **Staging Environment** : Environnement de pr√©-production
3. **Database Migrations** : Alembic pour migrations SQL
4. **Custom Domain** : Utiliser votre propre nom de domaine

---

## ‚úÖ Checklist de Fin d'Atelier

**Migration PostgreSQL :**
- [ ] SQLAlchemy et psycopg2 install√©s
- [ ] `database.py` cr√©√© avec configuration
- [ ] `models.py` cr√©√© avec TaskModel
- [ ] `app.py` migr√© pour utiliser la DB
- [ ] Tests adapt√©s avec base de test
- [ ] Tests locaux passent

**D√©ploiement :**
- [ ] Compte Render cr√©√©
- [ ] `render.yaml` compris
- [ ] Blueprint d√©ploy√© avec succ√®s
- [ ] Backend accessible via HTTPS
- [ ] Frontend accessible via HTTPS
- [ ] CORS configur√©
- [ ] PostgreSQL connect√©e

**Continuous Deployment :**
- [ ] Push d√©clenche GitHub Actions
- [ ] Tests passent automatiquement
- [ ] Render auto-deploy fonctionne
- [ ] Nouvelles fonctionnalit√©s visibles en prod
- [ ] Donn√©es persistent apr√®s red√©ploiement

**Si tout est coch√© : Bravo, vous ma√Ætrisez le cycle complet ! üéâüöÄ**

---

## üìö Ressources

**Documentation Technique :**
- [SQLAlchemy Docs](https://docs.sqlalchemy.org/)
- [FastAPI Database Guide](https://fastapi.tiangolo.com/tutorial/sql-databases/)
- [Render Blueprint Spec](https://render.com/docs/blueprint-spec)
- [PostgreSQL Docs](https://www.postgresql.org/docs/)

---

**Version 5.0** - TP 3 : Base de Donn√©es et D√©ploiement en Production (3h)
