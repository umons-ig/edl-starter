# üöÄ TP 3 : Base de Donn√©es et D√©ploiement en Production

## üéØ Objectifs de l'Atelier

√Ä la fin de cet atelier, vous aurez :

1. ‚úÖ Migr√© vers **PostgreSQL** avec SQLAlchemy ORM
2. ‚úÖ D√©ploy√© automatiquement avec **render.yaml** (Infrastructure as Code)
3. ‚úÖ Ajout√© de **nouvelles fonctionnalit√©s** (comptage de t√¢ches)
4. ‚úÖ V√©rifi√© le **d√©ploiement automatique** (Continuous Deployment)

---

## üì¶ Architecture Cible

**Avant (Local - Stockage en m√©moire) :**

```
Frontend (localhost:5173) ‚Üê ‚Üí Backend (localhost:8000)
                                  ‚Üì
                            Liste Python (RAM)
                            ‚ùå Donn√©es perdues au red√©marrage
```

**Apr√®s (Production avec PostgreSQL) :**

```
Frontend (Render)                Backend (Render)              Database (Supabase)
taskflow-frontend.onrender.com ‚Üí taskflow-backend.onrender.com ‚Üí PostgreSQL
         HTTPS                            HTTPS + CORS                500 MB
                                                                  ‚úÖ Donn√©es persistantes
```

---

## ‚úçÔ∏è Exercice 1 : Installer les D√©pendances PostgreSQL

### Objectif

Ajouter SQLAlchemy et le driver PostgreSQL au backend.

### Instructions

**Ajoutez les packages n√©cessaires :**

```bash
cd backend
uv add sqlalchemy psycopg2-binary
```

### üí° Ce que font ces packages

- **`sqlalchemy`** : ORM (Object-Relational Mapping) pour Python - permet de manipuler la base de donn√©es avec des objets Python
- **`psycopg2-binary`** : Driver PostgreSQL - permet √† Python de se connecter √† PostgreSQL

---

## ‚úçÔ∏è Exercice 2 : Configurer la Base de Donn√©es

### Objectif

Cr√©er le fichier de configuration pour la connexion √† la base de donn√©es.

### Instructions

**Cr√©ez le fichier `backend/src/database.py` :**

```python
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base

# Lire l'URL de la base de donn√©es depuis les variables d'environnement
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./taskflow.db")

# Configuration du moteur SQLAlchemy
if DATABASE_URL.startswith("sqlite"):
    # SQLite (d√©veloppement local)
    engine = create_engine(
        DATABASE_URL,
        connect_args={"check_same_thread": False}
    )
else:
    # PostgreSQL (production)
    engine = create_engine(
        DATABASE_URL,
        pool_size=5,
        max_overflow=10,
        pool_pre_ping=True
    )

# Factory de sessions
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base pour les mod√®les ORM
Base = declarative_base()


def get_db():
    """G√©n√©rateur qui fournit une session de base de donn√©es."""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def init_db():
    """Initialise la base de donn√©es en cr√©ant toutes les tables."""
    from . import models  # Import des mod√®les pour cr√©er les tables
    Base.metadata.create_all(bind=engine)
```

### üí° Points importants

- **`DATABASE_URL`** : URL de connexion (SQLite en local, PostgreSQL en production)
- **Pool de connexions** : R√©utilise les connexions pour am√©liorer les performances
- **`pool_pre_ping`** : V√©rifie que la connexion est vivante avant de l'utiliser

---

## ‚úçÔ∏è Exercice 3 : Cr√©er le Mod√®le de Donn√©es

### Objectif

D√©finir le sch√©ma de la table `tasks` avec SQLAlchemy ORM.

### Instructions

**Cr√©ez le fichier `backend/src/models.py` :**

```python
from enum import Enum
from sqlalchemy import Column, String, DateTime, Enum as SQLEnum
from sqlalchemy.sql import func

from .database import Base


class TaskStatus(str, Enum):
    """Statuts possibles d'une t√¢che."""
    TODO = "todo"
    IN_PROGRESS = "in_progress"
    DONE = "done"


class TaskPriority(str, Enum):
    """Priorit√©s possibles d'une t√¢che."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


class TaskModel(Base):
    """Mod√®le SQLAlchemy pour la table tasks."""
    __tablename__ = "tasks"

    id = Column(String, primary_key=True, index=True)
    title = Column(String(200), nullable=False)
    description = Column(String(1000), nullable=True)
    status = Column(SQLEnum(TaskStatus), default=TaskStatus.TODO)
    priority = Column(SQLEnum(TaskPriority), default=TaskPriority.MEDIUM)
    assignee = Column(String(100), nullable=True)
    due_date = Column(DateTime, nullable=True)
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
```

### üí° Avantages de l'ORM

- Pas besoin d'√©crire du SQL directement
- Type-safety avec Python
- Migrations de sch√©ma facilit√©es
- Timestamps automatiques (`created_at`, `updated_at`)

---

## ‚úçÔ∏è Exercice 4 : Migrer l'Application vers PostgreSQL

### Objectif

Adapter `app.py` pour utiliser SQLAlchemy au lieu du stockage en m√©moire.

### Contexte

Actuellement, `app.py` stocke les t√¢ches dans un dictionnaire Python (`tasks_db`). Au red√©marrage du serveur, toutes les donn√©es sont perdues. Nous allons migrer vers SQLAlchemy pour persister les donn√©es dans PostgreSQL.

### Instructions

**√âtape 1 : Mettre √† jour les imports**

Ouvrez `backend/src/app.py` et **ajoutez** les imports n√©cessaires (gardez les imports existants !) :

```python
from contextlib import asynccontextmanager
import uuid
from fastapi import Depends
from sqlalchemy.orm import Session
from sqlalchemy import text

from .database import get_db, init_db
from .models import TaskModel, TaskStatus, TaskPriority
```

üí° **Pourquoi ces imports ?**

- `Depends` : Injection de d√©pendances FastAPI pour la session DB
- `Session` : Type de la session SQLAlchemy
- `text` : Pour ex√©cuter du SQL brut (health check)
- `uuid` : Pour g√©n√©rer des identifiants uniques

**√âtape 2 : Nettoyer le code obsol√®te**

Cherchez et supprimez ces √©l√©ments dans `app.py` :

```python
# ‚ùå SUPPRIMER : Ces classes (lignes ~31-42)
class TaskStatus(str, Enum):
    TODO = "todo"
    ...

class TaskPriority(str, Enum):
    LOW = "low"
    ...

# ‚ùå SUPPRIMER : Le stockage en m√©moire (lignes ~78-79)
tasks_db: Dict[int, Task] = {}
next_id = 1

# ‚ùå SUPPRIMER : Ces fonctions (lignes ~82-94)
def get_next_id() -> int:
    ...

def clear_tasks():
    ...

# ‚ö†Ô∏è √Ä MODIFIER : Le health check (sera r√©√©crit √† l'√©tape 6)
@app.get("/health")
async def health_check():
    return {"status": "healthy", "tasks_count": len(tasks_db)}
```

> üí° Ces √©l√©ments sont maintenant dans `models.py` ou remplac√©s par SQLAlchemy.

**√âtape 3 : Remplacer le syst√®me de d√©marrage**

Cherchez et supprimez les anciens handlers :

```python
# ‚ùå SUPPRIMER ces deux fonctions (lignes ~129-139)
@app.on_event("startup")
def startup():
    ...

@app.on_event("shutdown")
def shutdown():
    ...
```

Remplacez-les par le nouveau syst√®me `lifespan` (√† placer AVANT la cr√©ation de `app`) :

```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifecycle manager - initialise la DB au d√©marrage."""
    logger.info("üöÄ TaskFlow backend starting up...")
    init_db()  # Cr√©e les tables
    logger.info("‚úÖ Database initialized")
    yield
    logger.info("üõë TaskFlow backend shutting down...")


app = FastAPI(
    title="TaskFlow API",
    ...
    lifespan=lifespan,  # ‚Üê Ajouter cette ligne
)
```

**√âtape 3b : Ajouter le middleware CORS**

Ajoutez ces imports en haut du fichier (avec les autres imports) :

```python
from fastapi.middleware.cors import CORSMiddleware
import os
```

Puis ajoutez ce code **juste apr√®s** `app = FastAPI(...)` :

```python
# Configuration CORS pour le frontend
cors_origins_str = os.getenv("CORS_ORIGINS", "http://localhost:5173,http://localhost:3000")
cors_origins = [origin.strip() for origin in cors_origins_str.split(",")]

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

> ‚ö†Ô∏è **Important** : Le middleware CORS est essentiel pour que le frontend puisse communiquer avec le backend en production. La variable `CORS_ORIGINS` sera configur√©e sur Render √† l'exercice 7.

**√âtape 4 : Modifier la classe Task existante**

Cherchez la classe `Task` dans `app.py` et remplacez-la :

```python
# ‚ùå AVANT (ne fonctionne plus avec SQLAlchemy)
class Task(TaskCreate):
    id: int  # ‚Üê int ne marche pas avec UUID
    created_at: datetime
    updated_at: datetime

# ‚úÖ APR√àS (compatible SQLAlchemy)
class Task(BaseModel):
    """Model for task response."""
    id: str  # ‚Üê Chang√© en str pour UUID
    title: str
    description: Optional[str] = None
    status: TaskStatus
    priority: TaskPriority
    assignee: Optional[str] = None
    due_date: Optional[datetime] = None
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True  # Permet la conversion depuis SQLAlchemy
```

> üí° **Pourquoi ces changements ?**
>
> - `id: str` au lieu de `int` ‚Üí les UUID sont des strings
> - `from_attributes = True` ‚Üí permet √† Pydantic de lire les objets SQLAlchemy

**√âtape 5 : Modifier les endpoints**

Pour chaque endpoint, ajoutez `db: Session = Depends(get_db)` comme param√®tre.

**Exemple simple avec health check :**

```python
# ‚ö†Ô∏è AVANT (ne fonctionne plus)
@app.get("/health")
async def health_check():
    return {"status": "healthy", "tasks_count": len(tasks_db)}

# ‚úÖ APR√àS (avec SQLAlchemy)
@app.get("/health")
async def health_check(db: Session = Depends(get_db)):
    """Health check with database status."""
    try:
        db.execute(text("SELECT 1"))
        tasks_count = db.query(TaskModel).count()
        return {
            "status": "healthy",
            "database": "connected",
            "tasks_count": tasks_count
        }
    except Exception as e:
        return {"status": "unhealthy", "database": str(e)}
```

> ‚ö†Ô∏è **Attention** : `db: Session = Depends(get_db)` doit √™tre dans les **param√®tres** de la fonction, pas dans le corps !

**Exemple complet avec GET /tasks :**

```python
@app.get("/tasks", response_model=List[Task])
async def get_tasks(
    status: Optional[TaskStatus] = None,
    priority: Optional[TaskPriority] = None,
    assignee: Optional[str] = None,
    db: Session = Depends(get_db)  # ‚Üê Toujours en dernier dans les param√®tres
):
    """Get all tasks with optional filtering."""
    query = db.query(TaskModel)

    if status:
        query = query.filter(TaskModel.status == status)
    if priority:
        query = query.filter(TaskModel.priority == priority)
    if assignee:
        query = query.filter(TaskModel.assignee == assignee)

    return query.all()
```

> ‚ö†Ô∏è **Ne confondez pas `Task` et `TaskModel` !**
>
> | Mod√®le | Type | Utilisation |
> |--------|------|-------------|
> | `Task` | Pydantic | `response_model=Task` (r√©ponses API) |
> | `TaskModel` | SQLAlchemy | `db.query(TaskModel)`, `TaskModel(...)` (op√©rations DB) |
>
> **R√®gle simple** : Pour tout ce qui touche √† la base de donn√©es ‚Üí `TaskModel`

Adaptez chaque endpoint selon ce tableau :

| Endpoint | Logique SQLAlchemy |
|----------|-------------------|
| GET /tasks | `db.query(TaskModel).all()` |
| GET /tasks/{id} | `db.query(TaskModel).filter(TaskModel.id == task_id).first()` |
| POST /tasks | `TaskModel(id=str(uuid.uuid4()), ...)` ‚Üí `db.add()` ‚Üí `db.commit()` ‚Üí `db.refresh()` |
| PUT /tasks/{id} | `setattr(task, field, value)` ‚Üí `db.commit()` ‚Üí `db.refresh(task)` |
| DELETE /tasks/{id} | `db.delete(task)` ‚Üí `db.commit()` |

> üí° **Pattern SQLAlchemy :**
>
> 1. `db.add(obj)` - Ajoute √† la session
> 2. `db.commit()` - Sauvegarde en base
> 3. `db.refresh(obj)` - Recharge les valeurs g√©n√©r√©es (timestamps, etc.)
>
> **Indice POST /tasks** : Cr√©ez un `TaskModel` (pas `Task`) avec `id=str(uuid.uuid4())` au lieu de `get_next_id()`

### üí° Points cl√©s √† retenir

| Concept | Explication |
|---------|-------------|
| `Depends(get_db)` | FastAPI injecte automatiquement une session DB |
| `db.commit()` | Obligatoire pour sauvegarder les changements |
| `db.refresh()` | Recharge l'objet avec les valeurs de la DB (timestamps) |
| `from_attributes = True` | Permet √† Pydantic de lire les attributs SQLAlchemy |

### ‚úÖ Checkpoint

Testez localement :

```bash
cd backend
uv run uvicorn src.app:app --reload

# Dans un autre terminal
curl http://localhost:8000/health
curl http://localhost:8000/tasks
```

Vous devriez voir un fichier `taskflow.db` cr√©√© dans `backend/`

---

## ‚úçÔ∏è Exercice 5 : Adapter les Tests

### Objectif

Modifier les tests pour utiliser une base de donn√©es SQLite temporaire.

### Contexte

Les tests utilisent actuellement `clear_tasks()` qui n'existe plus. Nous devons cr√©er une base de donn√©es de test isol√©e et nettoyer les donn√©es entre chaque test.

### Instructions

Remplacez le contenu de `backend/tests/conftest.py` par :

```python
import pytest
import tempfile
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import StaticPool

from src.app import app
from src.database import Base, get_db
from src.models import TaskModel

TEST_DB_FILE = tempfile.mktemp(suffix=".db")
TEST_DATABASE_URL = f"sqlite:///{TEST_DB_FILE}"

test_engine = create_engine(
    TEST_DATABASE_URL,
    connect_args={"check_same_thread": False},
    poolclass=StaticPool,
)

TestSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=test_engine)


@pytest.fixture(scope="session")
def setup_test_database():
    """Cr√©e les tables une seule fois pour tous les tests."""
    Base.metadata.create_all(bind=test_engine)
    yield
    Base.metadata.drop_all(bind=test_engine)


@pytest.fixture(autouse=True)
def clear_test_data(setup_test_database):
    """Nettoie les donn√©es entre chaque test."""
    db = TestSessionLocal()
    db.query(TaskModel).delete()
    db.commit()
    db.close()


@pytest.fixture
def client(setup_test_database):
    """Client de test avec base de donn√©es isol√©e."""
    def override_get_db():
        db = TestSessionLocal()
        try:
            yield db
        finally:
            db.close()

    app.dependency_overrides[get_db] = override_get_db
    with TestClient(app) as c:
        yield c
    app.dependency_overrides.clear()
```

> üí° **`dependency_overrides`** permet de remplacer `get_db` par une version qui utilise la base de test au lieu de la vraie base.

### ‚úÖ Checkpoint

```bash
cd backend
uv run pytest -v
```

Tous les tests doivent passer (19+ tests)

---

## ‚úçÔ∏è Exercice 6 : Configurer Supabase (Base de Donn√©es)

### Objectif

Cr√©er une base de donn√©es PostgreSQL gratuite sur Supabase.

### Instructions

**√âtape 1 : Cr√©er un compte Supabase**

1. Allez sur <https://supabase.com>
2. Cliquez **"Start your project"**
3. Inscrivez-vous avec votre compte **GitHub**

**√âtape 2 : Cr√©er un projet**

1. Cliquez **"New project"**
2. Configurez le projet :
   - **Name** : `taskflow`
   - **Database Password** : Choisissez un mot de passe fort (‚ö†Ô∏è **notez-le !**)
   - **Region** : `West EU (Ireland)` (le plus proche)
3. Cliquez **"Create new project"**
4. Attendez la cr√©ation (1-2 minutes)

Apr√®s la cr√©ation, vous arriverez sur la page d'accueil du projet :

![Supabase Home](img/supabase.png)

**√âtape 3 : R√©cup√©rer la DATABASE_URL**

1. Cliquez sur le bouton **"Connect"** en haut (visible dans le header)

   ![Supabase Connect](img/connect.png)

2. Dans l'onglet **Connection String** :
   - V√©rifiez que **Type** = `URI`
   - Changez **Method** : `Session pooler` (au lieu de "Direct connection")

   > ‚ö†Ô∏è **Important** : Render utilise IPv4, mais la connexion directe Supabase n√©cessite IPv6.
   > Le **Session Pooler** r√©sout ce probl√®me.

3. Copiez l'URL affich√©e
4. **Important** : Remplacez `[YOUR-PASSWORD]` par le mot de passe que vous avez choisi √† l'√©tape 2

L'URL ressemble √† :

```
postgresql://postgres.[PROJECT-ID]:[YOUR-PASSWORD]@aws-0-eu-west-1.pooler.supabase.com:5432/postgres
```

> üí° Notez le host **pooler.supabase.com** (au lieu de db.xxx.supabase.co).

**‚ö†Ô∏è Gardez cette URL !** Vous en aurez besoin pour l'exercice 7.

### üí° Pourquoi Supabase ?

| Avantage | Description |
|----------|-------------|
| **Gratuit** | 500 MB de stockage |
| **PostgreSQL** | Base de donn√©es professionnelle |
| **Interface web** | Explorer les donn√©es facilement |
| **Pas de carte bancaire** | Contrairement √† d'autres services |

---

## ‚úçÔ∏è Exercice 7 : D√©ployer sur Render

### Objectif

D√©ployer le backend et le frontend sur Render. Deux m√©thodes sont propos√©es.

### Pr√©requis

1. **Cr√©er un compte Render** : <https://render.com>
2. Inscrivez-vous avec **GitHub** et autorisez l'acc√®s √† vos repositories
3. **Poussez vos changements sur GitHub :**

   ```bash
   git add .
   git commit -m "feat: migrate to PostgreSQL with SQLAlchemy"
   git push origin main
   ```

---

### Option A : D√©ploiement Manuel (via Dashboard)

Cette m√©thode vous permet de comprendre chaque √©tape du d√©ploiement.

**√âtape 1 : D√©ployer le Backend**

1. Sur Render Dashboard, cliquez **"New +"** ‚Üí **"Web Service"**
2. Connectez votre repository GitHub
3. Configurez le service :

   | Param√®tre | Valeur |
   |-----------|--------|
   | **Name** | `taskflow-backend` |
   | **Region** | `Frankfurt (EU Central)` |
   | **Branch** | `main` |
   | **Root Directory** | `backend` |
   | **Runtime** | `Python 3` |
   | **Build Command** | `pip install uv && uv sync` |
   | **Start Command** | `uv run uvicorn src.app:app --host 0.0.0.0 --port $PORT` |
   | **Instance Type** | `Free` |

   > üí° `$PORT` est d√©fini automatiquement par Render - ne pas le remplacer !

4. Dans la section **Environment Variables**, ajoutez :

   | Name | Value |
   |------|-------|
   | `DATABASE_URL` | L'URL Supabase de l'exercice 6 |

   > ‚ö†Ô∏è `CORS_ORIGINS` sera ajout√© apr√®s le d√©ploiement du frontend (√©tape 3)

5. Cliquez **"Create Web Service"**

**√âtape 2 : D√©ployer le Frontend**

1. Cliquez **"New +"** ‚Üí **"Static Site"**
2. Connectez le m√™me repository
3. Configurez :

   | Param√®tre | Valeur |
   |-----------|--------|
   | **Name** | `taskflow-frontend` |
   | **Branch** | `main` |
   | **Root Directory** | `frontend` |
   | **Build Command** | `npm ci && npm run build` |
   | **Publish Directory** | `dist` |

4. Dans la section **Environment Variables**, ajoutez :

   | Name | Value |
   |------|-------|
   | `VITE_API_URL` | `https://edl-starter.onrender.com` (URL du backend) |

5. Cliquez **"Create Static Site"**

**√âtape 3 : Configurer CORS (apr√®s d√©ploiement)**

Une fois les deux services d√©ploy√©s, retournez dans le **Backend** :

1. Dashboard ‚Üí **taskflow-backend** ‚Üí **Environment**
2. Ajoutez la variable :

   | Name | Value |
   |------|-------|
   | `CORS_ORIGINS` | `https://taskflow-frontend-XXXX.onrender.com` |

3. Cliquez **"Save Changes"** ‚Üí Le backend red√©marre automatiquement

---

### Option B : D√©ploiement avec YAML (Infrastructure as Code)

Cette m√©thode automatise le d√©ploiement via un fichier de configuration.

**√âtape 1 : Cr√©er `render.yaml` √† la racine du projet**

```yaml
services:
  # Backend FastAPI
  - type: web
    name: taskflow-backend
    runtime: python
    region: frankfurt
    plan: free
    buildCommand: pip install uv && uv sync
    startCommand: uv run uvicorn src.app:app --host 0.0.0.0 --port $PORT
    rootDir: backend
    envVars:
      - key: DATABASE_URL
        sync: false  # Configur√© manuellement
      - key: CORS_ORIGINS
        sync: false
    healthCheckPath: /health

  # Frontend React
  - type: web
    name: taskflow-frontend
    runtime: static
    region: frankfurt
    plan: free
    buildCommand: npm ci && npm run build
    staticPublishPath: ./dist
    rootDir: frontend
    envVars:
      - key: VITE_API_URL
        sync: false
```

**√âtape 2 : D√©ployer avec Blueprint**

1. Poussez le fichier `render.yaml` sur GitHub
2. Sur Render Dashboard : **"New +"** ‚Üí **"Blueprint"**
3. S√©lectionnez votre repository
4. Render d√©tecte automatiquement `render.yaml`
5. Cliquez **"Apply"**

**√âtape 3 : Configurer les Variables d'Environnement**

M√™me configuration que l'Option A (voir ci-dessus).

---

### üí° Comparaison des deux m√©thodes

| Aspect | Option A (Manuel) | Option B (YAML) |
|--------|-------------------|-----------------|
| **Apprentissage** | ‚úÖ Meilleur pour comprendre | ‚ö° Plus rapide |
| **Reproductibilit√©** | ‚ùå Manuel √† chaque fois | ‚úÖ Versionn√© dans Git |
| **Production** | ‚ùå Pas recommand√© | ‚úÖ Best practice |

### ‚úÖ R√©sultat attendu

Apr√®s d√©ploiement, notez vos URLs :

```
Backend:  https://edl-starter.onrender.com
Frontend: https://taskflow-frontend-YYYY.onrender.com
```

### ‚è≥ Pendant l'attente (3-5 minutes)

Observez les logs de build en temps r√©el pour chaque service.

---

## ‚úçÔ∏è Exercice 8 : V√©rifier le D√©ploiement

### Objectif

Tester que tout fonctionne en production.

### Instructions

1. **Testez l'API Backend :**

   ```bash
   # Health check
   curl https://edl-starter.onrender.com/health
   ```

   Vous devriez voir :

   ```json
   {
     "status": "healthy",
     "database": "connected",
     "tasks_count": 0,
     "environment": "production"
   }
   ```

2. **Cr√©ez une t√¢che :**

   ```bash
   curl -X POST https://edl-starter.onrender.com/tasks \
     -H "Content-Type: application/json" \
     -d '{
       "title": "Test production",
       "status": "todo",
       "priority": "high"
     }'
   ```

3. **Listez les t√¢ches :**

   ```bash
   curl https://edl-starter.onrender.com/tasks
   ```

4. **Testez le Frontend :**
   - Ouvrez `https://taskflow-frontend-YYYY.onrender.com`
   - Cr√©ez plusieurs t√¢ches
   - Modifiez une t√¢che
   - Supprimez une t√¢che

### ‚úÖ R√©sultat attendu

Tout fonctionne parfaitement! üéâ

---

## üìã R√©capitulatif

F√©licitations ! Vous avez maintenant :

‚úÖ **Exercice 1** : Install√© SQLAlchemy et psycopg2
‚úÖ **Exercice 2** : Configur√© la connexion √† la base de donn√©es
‚úÖ **Exercice 3** : Cr√©√© le mod√®le ORM TaskModel
‚úÖ **Exercice 4** : Migr√© app.py vers PostgreSQL
‚úÖ **Exercice 5** : Adapt√© les tests avec une DB temporaire
‚úÖ **Exercice 6** : Configur√© Supabase (base de donn√©es PostgreSQL)
‚úÖ **Exercice 7** : D√©ploy√© sur Render
‚úÖ **Exercice 8** : V√©rifi√© le d√©ploiement en production

**Temps total estim√© :** 2h30

---

## üìö Ce que Vous Avez Appris

‚úÖ **SQLAlchemy ORM** - Mod√®les Python ‚Üî Tables SQL
‚úÖ **PostgreSQL** - Base de donn√©es relationnelle professionnelle
‚úÖ **D√©ploiement Cloud** - Backend et Frontend sur Render
‚úÖ **Base de donn√©es manag√©e** - Supabase pour PostgreSQL
‚úÖ **Variables d'environnement** - Configuration production vs d√©veloppement
‚úÖ **CORS** - Communication cross-origin frontend/backend
